{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IDEA_2_digits",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-p-_vQzOptb"
      },
      "source": [
        "## Imports + device + control randomness"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8xOf1jwNDDT"
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iyC-iUTFArQX",
        "outputId": "91c460f7-06aa-4e68-c49c-990aea498855"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZWAaoGrCu3c",
        "outputId": "ef508272-97e9-4d56-e1ff-c30fc5c1b390"
      },
      "source": [
        "dtype = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.float\n",
        "dtype"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkvxsMpCRZO2"
      },
      "source": [
        "torch.manual_seed(0)\n",
        "torch.cuda.manual_seed(0)\n",
        "\n",
        "random.seed(0)\n",
        "np.random.seed(0)\n",
        "\n",
        "torch.backends.cudnn.benchmark = False\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXYoyWVjCHtn"
      },
      "source": [
        ""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-cRFxiPSC2z"
      },
      "source": [
        "## Load data + \"Polish data\" - my heuristic"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_ZGAY-agt2M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "648892dc-230f-4a45-92a7-91fd199a22aa"
      },
      "source": [
        "def get_loader(train, batch_size=None):\n",
        "    '''\n",
        "    load MNIST dataset\n",
        "    '''\n",
        "    \n",
        "    # Dataset в PyTorch -- это какой-то объект, который оборачивает сырые данные и делает с ними какой-нибудь препроцессинг\n",
        "    dataset = datasets.MNIST('mnist', train=train, download=True,\n",
        "        transform=transforms.ToTensor())\n",
        "    \n",
        "    if batch_size is None:\n",
        "        batch_size = 1\n",
        "\n",
        "    loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    return loader\n",
        "\n",
        "train = get_loader(True, 64)\n",
        "val = get_loader(False, 64)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
            "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yPBongS550N"
      },
      "source": [
        "def polish_data(loader, batch_size=None, p=None):\n",
        "    '''\n",
        "    list of [X, y] tensors (X = 1 * 1 * 28 * 28, y = 1 * 1) to\n",
        "    shuffled list of [batch_size * 1 * X * 28, batch_size * 1] \n",
        "    but p = % of samples in data -> used to cut data from MNIST\n",
        "    and changing cut data for better performance\n",
        "    '''\n",
        "\n",
        "    if p is None:\n",
        "        '''\n",
        "        if p is None -> change nothing \n",
        "        '''\n",
        "        return loader\n",
        "\n",
        "    assert np.abs(np.sum(p, axis=None) - 1) < 0.0001, 'wrong p'\n",
        "    p = p*2\n",
        "\n",
        "    # count of each target -> new len\n",
        "    cnt = [0] * 2\n",
        "    all_len = 0\n",
        "    for X, y in loader:\n",
        "        y_ = int(y)\n",
        "        if y_ <= 1:              \n",
        "            cnt[y_] += 1\n",
        "            all_len += 1\n",
        "    new_len = np.min(cnt / p, axis=None)\n",
        "\n",
        "    # max_target_size for each target\n",
        "    max_target_size = [int(i) for i in p * new_len]\n",
        "\n",
        "    # maybe some heuristics to avoid ~zero max_targets_size\n",
        "\n",
        "    # new lists\n",
        "    lists = [[] for i in range(2)]\n",
        "    for X, y in loader:\n",
        "        y_ = int(y)\n",
        "        if y_ <= 1:\n",
        "            if len(lists[y_]) < max_target_size[y_]:\n",
        "                lists[y_].append(torch.reshape(X, (1, 28, 28)))\n",
        "\n",
        "    # unite and shuffle\n",
        "    united = []\n",
        "    print('cnt_0 =', len(lists[0]))\n",
        "    print('cnt_1 =', len(lists[1]))\n",
        "    for y in range(2):\n",
        "        for X in lists[y]:\n",
        "            united.append([X, y])\n",
        "    np.random.shuffle(united)\n",
        "\n",
        "    # group to batches\n",
        "    batch_X = []\n",
        "    batch_y = []\n",
        "    all_batches = []\n",
        "\n",
        "    if batch_size is None:\n",
        "        batch_size = np.sum(max_target_size, axis=None)\n",
        "    for X, y in united:\n",
        "        batch_X.append(X)\n",
        "        batch_y.append(y)\n",
        "        if len(batch_X) == batch_size:\n",
        "            tt1 = torch.stack(batch_X)\n",
        "            tt2 = torch.Tensor(batch_y)\n",
        "            all_batches.append([tt1, tt2.type(torch.LongTensor)])\n",
        "            batch_X = []\n",
        "            batch_y = []\n",
        "    # no 'cutted-batches'\n",
        "\n",
        "    return all_batches"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOZn45I8FKi7",
        "outputId": "9deac0af-787f-4648-b9f7-7daa8606ae5e"
      },
      "source": [
        "'''\n",
        "MNIST has (by default) approximately equal amount of samples for each target ->\n",
        "I need to create disbalanced dataset so t_ and v_ are disbalanced data from MNIST\n",
        "'''\n",
        "one = 1 # always 1\n",
        "t_ = polish_data(get_loader(True, batch_size=one), batch_size=one, p=np.array([0.2, 0.8]))\n",
        "v_ = polish_data(get_loader(False, batch_size=one), batch_size=one, p=np.array([0.5, 0.5]))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cnt_0 = 1685\n",
            "cnt_1 = 6742\n",
            "cnt_0 = 980\n",
            "cnt_1 = 980\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPkc6FqahH2-"
      },
      "source": [
        "'''\n",
        "Split disbalanced to samples for training (p is None by default) so no transformations there\n",
        "'''\n",
        "train = polish_data(t_, batch_size=10)\n",
        "val = polish_data(v_, batch_size=10)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqFNjbnh1xOu"
      },
      "source": [
        "def accuracy(model, val):\n",
        "    '''\n",
        "    accuracy of predictions\n",
        "    '''\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for X, y in val:\n",
        "        res = model(X.to(device))\n",
        "        res = res.argmax(dim=1)\n",
        "        total += res.shape[0]\n",
        "        correct += (res == y.to(device)).sum().item()\n",
        "    return correct / total"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-u71Ran0PXs_"
      },
      "source": [
        "## Basic fit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DN_rWUgzRZ_p"
      },
      "source": [
        "torch.manual_seed(0)\n",
        "torch.cuda.manual_seed(0)\n",
        "\n",
        "random.seed(0)\n",
        "np.random.seed(0)\n",
        "\n",
        "torch.backends.cudnn.benchmark = False\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2QxTRLvdg4r"
      },
      "source": [
        "'''\n",
        "simple linear regression for better illustration, complex models\n",
        "(especially with conv layers will converge too fast and wouldn't show advantage of heuristic)\n",
        "'''\n",
        "model_base = nn.Sequential(\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(28*28, 2)\n",
        ")\n",
        "\n",
        "optimizer = torch.optim.Adam(model_base.parameters(), lr=0.001)\n",
        "criterion = nn.NLLLoss()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y664HTavPHJL",
        "outputId": "607f0a1e-dc54-40f8-ee6e-09fa3e67b1d8"
      },
      "source": [
        "for epoch in range(10):\n",
        "    for X, y in train:\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output = model_base(X.to(device))\n",
        "        loss = criterion(output, y.to(device))\n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "    \n",
        "    print(accuracy(model_base, train), accuracy(model_base, val))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9621454847513943 0.9280612244897959\n",
            "0.9635694790554171 0.9306122448979591\n",
            "0.9635694790554171 0.9311224489795918\n",
            "0.9641628100154266 0.9311224489795918\n",
            "0.9642814762074285 0.9311224489795918\n",
            "0.9642814762074285 0.9311224489795918\n",
            "0.9642814762074285 0.9311224489795918\n",
            "0.9642814762074285 0.9311224489795918\n",
            "0.9642814762074285 0.9311224489795918\n",
            "0.9642814762074285 0.9311224489795918\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkcWwOcHcyIt",
        "outputId": "e2cd6921-02e8-4d1d-880f-2d9f1284fc8d"
      },
      "source": [
        "print(round(accuracy(model_base, val) * 100, 2), '%', sep='') # poor"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "93.11%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8y_L5TrRc-9m"
      },
      "source": [
        "## My special heuristic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WX5oxbLreMgH"
      },
      "source": [
        "Read description of heuristic via .README"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6bAOJZ1l_XQ"
      },
      "source": [
        "torch.manual_seed(0)\n",
        "np.random.seed(0)\n",
        "random.seed(0)\n",
        "\n",
        "torch.backends.cudnn.benchmark = False\n",
        "torch.cuda.manual_seed(0)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGUQ35akasMD"
      },
      "source": [
        "def target_preds_density(model, val):\n",
        "    ans = [0] * 2\n",
        "    for X, y in val:\n",
        "        res = model(X.to(device))\n",
        "        res = res.argmax(dim=1)\n",
        "        for i in res:\n",
        "            ans[i] += 1\n",
        "\n",
        "    return ans"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3f3qGubndTCj"
      },
      "source": [
        "model_heuristic = nn.Sequential(\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(28*28, 2)\n",
        ").to(device)\n",
        "\n",
        "# same optimizer and criterion\n",
        "optimizer = torch.optim.Adam(model_heuristic.parameters(), lr=0.001)\n",
        "criterion = nn.NLLLoss()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qT9SXb1LPHE6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad5de20e-19ab-44c2-dbbf-c51d76ad7084"
      },
      "source": [
        "p = None\n",
        "pr_p = None\n",
        "for epoch in range(10):\n",
        "    train = polish_data(t_, 10, p)\n",
        "\n",
        "    for X, y in train:\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output = model_heuristic(X.to(device))\n",
        "        loss = criterion(output, y.to(device))\n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "    \n",
        "    print(accuracy(model_heuristic, train), accuracy(model_heuristic, val))\n",
        "\n",
        "    # 1) get percentages for 0..2\n",
        "    val_preds = target_preds_density(model_heuristic, val)\n",
        "    p = val_preds / np.sum(val_preds, axis=None)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9621454847513943 0.9280612244897959\n",
            "cnt_0 = 1685\n",
            "cnt_1 = 2251\n",
            "0.9498727735368957 0.9566326530612245\n",
            "cnt_0 = 1685\n",
            "cnt_1 = 2005\n",
            "0.9672086720867209 0.9739795918367347\n",
            "cnt_0 = 1685\n",
            "cnt_1 = 1870\n",
            "0.9783098591549296 0.9826530612244898\n",
            "cnt_0 = 1685\n",
            "cnt_1 = 1806\n",
            "0.9828080229226361 0.9887755102040816\n",
            "cnt_0 = 1685\n",
            "cnt_1 = 1762\n",
            "0.9863372093023256 0.9923469387755102\n",
            "cnt_0 = 1685\n",
            "cnt_1 = 1737\n",
            "0.9897660818713451 0.9933673469387755\n",
            "cnt_0 = 1685\n",
            "cnt_1 = 1723\n",
            "0.9905882352941177 0.9948979591836735\n",
            "cnt_0 = 1685\n",
            "cnt_1 = 1712\n",
            "0.9914454277286135 0.9954081632653061\n",
            "cnt_0 = 1685\n",
            "cnt_1 = 1709\n",
            "0.9920353982300885 0.9959183673469387\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOoCgmz4gt22",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85650300-3b13-4e51-8c72-d168b895bac6"
      },
      "source": [
        "print(round(accuracy(model_heuristic, val) * 100, 2), '%', sep='') # strong"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99.59%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqs_1M5H9wR7"
      },
      "source": [
        ""
      ],
      "execution_count": 18,
      "outputs": []
    }
  ]
}